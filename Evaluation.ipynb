{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. most popular 1000 Python Github repo\n",
    "2. filter top N frequently asked questions on StackOverflow(17000->2000) (question viewed+votes)\n",
    "3. Verify if the StackOverflow code snippet exist in 1000 repo\n",
    "    - ElasticSearch\n",
    "    - manually choose 100 questions from ElasticSearch result\n",
    "4. use StackOverflow questions as input of the model, and manually evalute if the top 10 results has correct ansers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Evaluation 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replaced the 4th step of the earlier evaluation methods with:<br>\n",
    "- first taking the top 10 results retrieved by NCS, and for each retrieved method, getting a similarity score between the groundâ€“truth code snippet and the method. \n",
    "- choose a threshold that minimize false positive\n",
    "=>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path to target files\n",
    "st=time()\n",
    "path_wordembedding=\"data/embeddings.txt\"\n",
    "path_docembedding=\"data/document_embeddings.csv\"\n",
    "path_stackoverflow=\"data/stack_overflow/StackOverFlow.csv\"\n",
    "\n",
    "# change hyperparameters\n",
    "vocab_size=500\n",
    "window_size=5\n",
    "\n",
    "#StackOverflow start id\n",
    "start_idx=0\n",
    "end_idx=10 #will actually run to end_idx-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of StackOverflow data: (1305, 6)\n",
      "Run time: 0.07717013359069824 s\n"
     ]
    }
   ],
   "source": [
    "# load StackOverflow data\n",
    "st=time()\n",
    "df_stack_overflow=pd.read_csv(path_stackoverflow)\n",
    "print(\"Dimension of StackOverflow data: {}\".format(df_stack_overflow.shape))\n",
    "print(\"Run time: {} s\".format(time()-st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 1.0715551376342773 s\n"
     ]
    }
   ],
   "source": [
    "# load wordembedding: representation of words\n",
    "st=time()\n",
    "trained_ft_vectors = KeyedVectors.load_word2vec_format(path_wordembedding)\n",
    "print(\"Run time: {} s\".format(time()-st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the document embedding: (1038, 500)\n",
      "Run time: 0.48323917388916016 s\n"
     ]
    }
   ],
   "source": [
    "# load document embedding: representation of each source code function\n",
    "st=time()\n",
    "document_embeddings=np.loadtxt(fname=path_docembedding, delimiter=\",\")\n",
    "print(\"Dimension of the document embedding: {}\".format(document_embeddings.shape))\n",
    "print(\"Run time: {} s\".format(time()-st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize a word represenatation vector that its L2 norm is 1.\n",
    "# we do this so that the cosine similarity reduces to a simple dot product\n",
    "\n",
    "def normalize(word_representations):\n",
    "    for word in word_representations:\n",
    "        total=0\n",
    "        for key in word_representations[word]:\n",
    "            total+=word_representations[word][key]*word_representations[word][key]\n",
    "            \n",
    "        total=math.sqrt(total)\n",
    "        for key in word_representations[word]:\n",
    "            word_representations[word][key]/=total\n",
    "\n",
    "def dictionary_dot_product(dict1, dict2):\n",
    "    dot=0\n",
    "    for key in dict1:\n",
    "        if key in dict2:\n",
    "            dot+=dict1[key]*dict2[key]\n",
    "    return dot\n",
    "\n",
    "def find_sim(word_representations, query):\n",
    "    if query not in word_representations:\n",
    "        print(\"'%s' is not in vocabulary\" % query)\n",
    "        return None\n",
    "    \n",
    "    scores={}\n",
    "    for word in word_representations:\n",
    "        cosine=dictionary_dot_product(word_representations[query], word_representations[word])\n",
    "        scores[word]=cosine\n",
    "    return scores\n",
    "\n",
    "# Find the K words with highest cosine similarity to a query in a set of word_representations\n",
    "def find_nearest_neighbors(word_representations, query, K):\n",
    "    scores=find_sim(word_representations, query)\n",
    "    if scores != None:\n",
    "        sorted_x = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        for idx, (k, v) in enumerate(sorted_x[:K]):\n",
    "            print(\"%s\\t%s\\t%.5f\" % (idx,k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_relevant_document(question, word_embedding, doc_embedding, num=10):\n",
    "    \"\"\"Return the functions that are most relevant to the natual language question.\n",
    "\n",
    "    Args:\n",
    "        question: A string. A Question from StackOverflow. \n",
    "        word_embedding: Word embedding generated from codebase.\n",
    "        doc_embedding: Document embedding generated from codebase\n",
    "        num: The number of top similar functions to return.\n",
    "\n",
    "    Returns:\n",
    "        A list of indices of the top NUM related functions to the QUESTION in the WORD_EMBEDDING.\n",
    "    \n",
    "    \"\"\"\n",
    "    # convert QUESTION to a vector\n",
    "    tokenized_ques=question.split()\n",
    "    vec_ques=np.zeros((1,document_embeddings.shape[1])) #vocab_size\n",
    "    token_count=0\n",
    "    has_token_in_embedding=False\n",
    "    for token in tokenized_ques:\n",
    "        if token in word_embedding:\n",
    "            has_token_in_embedding=True\n",
    "            vec_ques+=word_embedding[token]\n",
    "            token_count+=1\n",
    "    \n",
    "    if has_token_in_embedding:\n",
    "        mean_vec_ques=vec_ques/token_count\n",
    "    \n",
    "    \n",
    "        # compute similarity between this question and each of the source code snippets\n",
    "        cosine_sim=[]\n",
    "        for idx, doc in enumerate(document_embeddings):\n",
    "            #[TODO] fix dimension\n",
    "\n",
    "            try:\n",
    "                cosine_sim.append(cosine_similarity(mean_vec_ques, doc.reshape(1, -1))[0][0])\n",
    "            except ValueError:\n",
    "                print(question)\n",
    "                print(vec_ques, token_count)\n",
    "                print(mean_vec_ques)\n",
    "                print(doc.reshape(1, -1))\n",
    "        # get top `num` similar functions\n",
    "        result_func_id=np.array(cosine_sim).argsort()[-num:][::-1]\n",
    "        result_similarity=np.sort(np.array(cosine_sim))[-num:][::-1]\n",
    "    else:\n",
    "        result_func_id=np.nan\n",
    "        result_similarity=np.nan\n",
    "    return result_func_id, result_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit number of questions\n",
    "df_stack_overflow_partial=df_stack_overflow.iloc[start_idx:end_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 1.6584300994873047 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/winnielee/code/.virtualenvs/capstone/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/winnielee/code/.virtualenvs/capstone/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "st=time()\n",
    "list_most_relevant_doc=[]\n",
    "list_most_relevant_sim=[]\n",
    "for idx in range(len(df_stack_overflow_partial)): \n",
    "    question=df_stack_overflow_partial.iloc[idx][\"Question_Title\"]\n",
    "    \n",
    "    most_relevant_doc, most_relevant_sim=get_most_relevant_document(question, trained_ft_vectors, document_embeddings)\n",
    "    list_most_relevant_doc.append(most_relevant_doc)\n",
    "    list_most_relevant_sim.append(most_relevant_sim)\n",
    "df_stack_overflow_partial[\"func_id\"]=list_most_relevant_doc\n",
    "df_stack_overflow_partial[\"sim\"]=list_most_relevant_sim\n",
    "print(\"Run time: {} s\".format(time()-st)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "df_stack_overflow_partial.to_pickle(\"data/SO_similarity_{}_{}.pkl\".format(start_idx, end_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post_Link_ID</th>\n",
       "      <th>Question_Score</th>\n",
       "      <th>Question_Title</th>\n",
       "      <th>Question_Content</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Tags</th>\n",
       "      <th>func_id</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50607128</td>\n",
       "      <td>47</td>\n",
       "      <td>Creating a nested dictionary from a flattened ...</td>\n",
       "      <td>&lt;p&gt;I have a flattened dictionary which I want ...</td>\n",
       "      <td>def nest_dict(flat):\\n    result = {}\\n    for...</td>\n",
       "      <td>&lt;python&gt;&lt;dictionary&gt;&lt;recursion&gt;&lt;nested&gt;&lt;netcdf&gt;</td>\n",
       "      <td>[377, 421, 448, 371, 456, 100, 920, 150, 346, ...</td>\n",
       "      <td>[0.9999984771395396, 0.9999984686083946, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45631715</td>\n",
       "      <td>36</td>\n",
       "      <td>Downloading with chrome headless and selenium</td>\n",
       "      <td>&lt;p&gt;I'm using python-selenium and Chrome 59 and...</td>\n",
       "      <td>def enable_download_in_headless_chrome(self, d...</td>\n",
       "      <td>&lt;python&gt;&lt;google-chrome&gt;&lt;selenium&gt;&lt;google-chrom...</td>\n",
       "      <td>[116, 416, 92, 1004, 258, 117, 102, 409, 430, ...</td>\n",
       "      <td>[0.9999992941886049, 0.9999992261907498, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43957860</td>\n",
       "      <td>17</td>\n",
       "      <td>Python unittest - Ran 0 tests in 0.000s</td>\n",
       "      <td>&lt;p&gt;So I want to do this code &lt;a href=\"http://o...</td>\n",
       "      <td>def test_add_returns_zero_for_emptyString(self...</td>\n",
       "      <td>&lt;python&gt;&lt;unit-testing&gt;&lt;python-unittest&gt;&lt;python...</td>\n",
       "      <td>[2, 932, 929, 107, 313, 258, 255, 477, 458, 290]</td>\n",
       "      <td>[0.9999963140780601, 0.9999960986804608, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44424040</td>\n",
       "      <td>16</td>\n",
       "      <td>Django logging custom attributes in formatter</td>\n",
       "      <td>&lt;p&gt;How can Django use logging to log using cus...</td>\n",
       "      <td>def add_my_custom_attribute(record):\\n    reco...</td>\n",
       "      <td>&lt;python&gt;&lt;django&gt;&lt;logging&gt;</td>\n",
       "      <td>[2, 258, 530, 289, 108, 117, 932, 290, 288, 489]</td>\n",
       "      <td>[0.9999994069389221, 0.9999993391644111, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48019843</td>\n",
       "      <td>14</td>\n",
       "      <td>PCA on word2vec embeddings</td>\n",
       "      <td>&lt;p&gt;I am trying to reproduce the results of thi...</td>\n",
       "      <td>def doPCA(pairs, embedding, num_components = 1...</td>\n",
       "      <td>&lt;python&gt;&lt;scikit-learn&gt;&lt;nlp&gt;&lt;pca&gt;&lt;word2vec&gt;</td>\n",
       "      <td>[349, 348, 497, 494, 498, 516, 527, 518, 519, ...</td>\n",
       "      <td>[0.9999985864775749, 0.9999984819488087, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42381902</td>\n",
       "      <td>13</td>\n",
       "      <td>Interpreting negative Word2Vec similarity from...</td>\n",
       "      <td>&lt;p&gt;E.g. we train a word2vec model using &lt;code&gt;...</td>\n",
       "      <td>def similarity(self, w1, w2):\\n    \"\"\"\\n    Co...</td>\n",
       "      <td>&lt;python&gt;&lt;nlp&gt;&lt;similarity&gt;&lt;gensim&gt;&lt;word2vec&gt;</td>\n",
       "      <td>[1011, 989, 990, 992, 993, 994, 991, 1003, 71,...</td>\n",
       "      <td>[0.9999976629195375, 0.999997407998317, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43855162</td>\n",
       "      <td>13</td>\n",
       "      <td>RMSE/ RMSLE loss function in Keras</td>\n",
       "      <td>&lt;p&gt;I try to participate in my first Kaggle com...</td>\n",
       "      <td>def root_mean_squared_error(y_true, y_pred):\\n...</td>\n",
       "      <td>&lt;python&gt;&lt;keras&gt;&lt;custom-function&gt;&lt;loss-function&gt;</td>\n",
       "      <td>[2, 258, 290, 932, 289, 117, 288, 175, 150, 108]</td>\n",
       "      <td>[0.999999246929511, 0.9999992116031092, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50253517</td>\n",
       "      <td>11</td>\n",
       "      <td>How to group functions without side effects?</td>\n",
       "      <td>&lt;p&gt;I have a function with several helper funct...</td>\n",
       "      <td>def create_filled_template_in_temp(path, value...</td>\n",
       "      <td>&lt;python&gt;</td>\n",
       "      <td>[433, 230, 973, 490, 425, 523, 515, 928, 477, ...</td>\n",
       "      <td>[0.9999991215290384, 0.999999073228489, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43791970</td>\n",
       "      <td>11</td>\n",
       "      <td>Pandas: assigning columns with multiple condit...</td>\n",
       "      <td>&lt;p&gt;Edited:&lt;/p&gt;\\n\\n&lt;p&gt;I have a financial portfo...</td>\n",
       "      <td>def closure():\\n    cur_weight = {}\\n    def f...</td>\n",
       "      <td>&lt;python&gt;&lt;pandas&gt;&lt;dataframe&gt;&lt;finance&gt;&lt;portfolio&gt;</td>\n",
       "      <td>[116, 117, 108, 256, 543, 1004, 934, 427, 92, ...</td>\n",
       "      <td>[0.9999995954184046, 0.9999995363726762, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44293479</td>\n",
       "      <td>11</td>\n",
       "      <td>Python, I'm repeating myself a lot when it com...</td>\n",
       "      <td>&lt;p&gt;Lets say I have three lists and I need to i...</td>\n",
       "      <td>def get_average(streaks):\\n    streak_0_num0s ...</td>\n",
       "      <td>&lt;python&gt;&lt;for-loop&gt;&lt;dry&gt;</td>\n",
       "      <td>[419, 102, 101, 100, 104, 425, 363, 523, 372, ...</td>\n",
       "      <td>[0.9999995399367301, 0.9999995397426804, 0.999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Post_Link_ID  Question_Score  \\\n",
       "0      50607128              47   \n",
       "1      45631715              36   \n",
       "2      43957860              17   \n",
       "3      44424040              16   \n",
       "4      48019843              14   \n",
       "5      42381902              13   \n",
       "6      43855162              13   \n",
       "7      50253517              11   \n",
       "8      43791970              11   \n",
       "9      44293479              11   \n",
       "\n",
       "                                      Question_Title  \\\n",
       "0  Creating a nested dictionary from a flattened ...   \n",
       "1      Downloading with chrome headless and selenium   \n",
       "2            Python unittest - Ran 0 tests in 0.000s   \n",
       "3      Django logging custom attributes in formatter   \n",
       "4                         PCA on word2vec embeddings   \n",
       "5  Interpreting negative Word2Vec similarity from...   \n",
       "6                 RMSE/ RMSLE loss function in Keras   \n",
       "7       How to group functions without side effects?   \n",
       "8  Pandas: assigning columns with multiple condit...   \n",
       "9  Python, I'm repeating myself a lot when it com...   \n",
       "\n",
       "                                    Question_Content  \\\n",
       "0  <p>I have a flattened dictionary which I want ...   \n",
       "1  <p>I'm using python-selenium and Chrome 59 and...   \n",
       "2  <p>So I want to do this code <a href=\"http://o...   \n",
       "3  <p>How can Django use logging to log using cus...   \n",
       "4  <p>I am trying to reproduce the results of thi...   \n",
       "5  <p>E.g. we train a word2vec model using <code>...   \n",
       "6  <p>I try to participate in my first Kaggle com...   \n",
       "7  <p>I have a function with several helper funct...   \n",
       "8  <p>Edited:</p>\\n\\n<p>I have a financial portfo...   \n",
       "9  <p>Lets say I have three lists and I need to i...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  def nest_dict(flat):\\n    result = {}\\n    for...   \n",
       "1  def enable_download_in_headless_chrome(self, d...   \n",
       "2  def test_add_returns_zero_for_emptyString(self...   \n",
       "3  def add_my_custom_attribute(record):\\n    reco...   \n",
       "4  def doPCA(pairs, embedding, num_components = 1...   \n",
       "5  def similarity(self, w1, w2):\\n    \"\"\"\\n    Co...   \n",
       "6  def root_mean_squared_error(y_true, y_pred):\\n...   \n",
       "7  def create_filled_template_in_temp(path, value...   \n",
       "8  def closure():\\n    cur_weight = {}\\n    def f...   \n",
       "9  def get_average(streaks):\\n    streak_0_num0s ...   \n",
       "\n",
       "                                                Tags  \\\n",
       "0    <python><dictionary><recursion><nested><netcdf>   \n",
       "1  <python><google-chrome><selenium><google-chrom...   \n",
       "2  <python><unit-testing><python-unittest><python...   \n",
       "3                          <python><django><logging>   \n",
       "4         <python><scikit-learn><nlp><pca><word2vec>   \n",
       "5        <python><nlp><similarity><gensim><word2vec>   \n",
       "6    <python><keras><custom-function><loss-function>   \n",
       "7                                           <python>   \n",
       "8    <python><pandas><dataframe><finance><portfolio>   \n",
       "9                            <python><for-loop><dry>   \n",
       "\n",
       "                                             func_id  \\\n",
       "0  [377, 421, 448, 371, 456, 100, 920, 150, 346, ...   \n",
       "1  [116, 416, 92, 1004, 258, 117, 102, 409, 430, ...   \n",
       "2   [2, 932, 929, 107, 313, 258, 255, 477, 458, 290]   \n",
       "3   [2, 258, 530, 289, 108, 117, 932, 290, 288, 489]   \n",
       "4  [349, 348, 497, 494, 498, 516, 527, 518, 519, ...   \n",
       "5  [1011, 989, 990, 992, 993, 994, 991, 1003, 71,...   \n",
       "6   [2, 258, 290, 932, 289, 117, 288, 175, 150, 108]   \n",
       "7  [433, 230, 973, 490, 425, 523, 515, 928, 477, ...   \n",
       "8  [116, 117, 108, 256, 543, 1004, 934, 427, 92, ...   \n",
       "9  [419, 102, 101, 100, 104, 425, 363, 523, 372, ...   \n",
       "\n",
       "                                                 sim  \n",
       "0  [0.9999984771395396, 0.9999984686083946, 0.999...  \n",
       "1  [0.9999992941886049, 0.9999992261907498, 0.999...  \n",
       "2  [0.9999963140780601, 0.9999960986804608, 0.999...  \n",
       "3  [0.9999994069389221, 0.9999993391644111, 0.999...  \n",
       "4  [0.9999985864775749, 0.9999984819488087, 0.999...  \n",
       "5  [0.9999976629195375, 0.999997407998317, 0.9999...  \n",
       "6  [0.999999246929511, 0.9999992116031092, 0.9999...  \n",
       "7  [0.9999991215290384, 0.999999073228489, 0.9999...  \n",
       "8  [0.9999995954184046, 0.9999995363726762, 0.999...  \n",
       "9  [0.9999995399367301, 0.9999995397426804, 0.999...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stack_overflow_partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post_Link_ID</th>\n",
       "      <th>Question_Score</th>\n",
       "      <th>Question_Title</th>\n",
       "      <th>Question_Content</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Tags</th>\n",
       "      <th>func_id</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50607128</td>\n",
       "      <td>47</td>\n",
       "      <td>Creating a nested dictionary from a flattened ...</td>\n",
       "      <td>&lt;p&gt;I have a flattened dictionary which I want ...</td>\n",
       "      <td>def nest_dict(flat):\\n    result = {}\\n    for...</td>\n",
       "      <td>&lt;python&gt;&lt;dictionary&gt;&lt;recursion&gt;&lt;nested&gt;&lt;netcdf&gt;</td>\n",
       "      <td>[377, 421, 448, 371, 456, 100, 920, 150, 346, ...</td>\n",
       "      <td>[0.9999984771395396, 0.9999984686083946, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45631715</td>\n",
       "      <td>36</td>\n",
       "      <td>Downloading with chrome headless and selenium</td>\n",
       "      <td>&lt;p&gt;I'm using python-selenium and Chrome 59 and...</td>\n",
       "      <td>def enable_download_in_headless_chrome(self, d...</td>\n",
       "      <td>&lt;python&gt;&lt;google-chrome&gt;&lt;selenium&gt;&lt;google-chrom...</td>\n",
       "      <td>[116, 416, 92, 1004, 258, 117, 102, 409, 430, ...</td>\n",
       "      <td>[0.9999992941886049, 0.9999992261907498, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43957860</td>\n",
       "      <td>17</td>\n",
       "      <td>Python unittest - Ran 0 tests in 0.000s</td>\n",
       "      <td>&lt;p&gt;So I want to do this code &lt;a href=\"http://o...</td>\n",
       "      <td>def test_add_returns_zero_for_emptyString(self...</td>\n",
       "      <td>&lt;python&gt;&lt;unit-testing&gt;&lt;python-unittest&gt;&lt;python...</td>\n",
       "      <td>[2, 932, 929, 107, 313, 258, 255, 477, 458, 290]</td>\n",
       "      <td>[0.9999963140780601, 0.9999960986804608, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44424040</td>\n",
       "      <td>16</td>\n",
       "      <td>Django logging custom attributes in formatter</td>\n",
       "      <td>&lt;p&gt;How can Django use logging to log using cus...</td>\n",
       "      <td>def add_my_custom_attribute(record):\\n    reco...</td>\n",
       "      <td>&lt;python&gt;&lt;django&gt;&lt;logging&gt;</td>\n",
       "      <td>[2, 258, 530, 289, 108, 117, 932, 290, 288, 489]</td>\n",
       "      <td>[0.9999994069389221, 0.9999993391644111, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48019843</td>\n",
       "      <td>14</td>\n",
       "      <td>PCA on word2vec embeddings</td>\n",
       "      <td>&lt;p&gt;I am trying to reproduce the results of thi...</td>\n",
       "      <td>def doPCA(pairs, embedding, num_components = 1...</td>\n",
       "      <td>&lt;python&gt;&lt;scikit-learn&gt;&lt;nlp&gt;&lt;pca&gt;&lt;word2vec&gt;</td>\n",
       "      <td>[349, 348, 497, 494, 498, 516, 527, 518, 519, ...</td>\n",
       "      <td>[0.9999985864775749, 0.9999984819488087, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42381902</td>\n",
       "      <td>13</td>\n",
       "      <td>Interpreting negative Word2Vec similarity from...</td>\n",
       "      <td>&lt;p&gt;E.g. we train a word2vec model using &lt;code&gt;...</td>\n",
       "      <td>def similarity(self, w1, w2):\\n    \"\"\"\\n    Co...</td>\n",
       "      <td>&lt;python&gt;&lt;nlp&gt;&lt;similarity&gt;&lt;gensim&gt;&lt;word2vec&gt;</td>\n",
       "      <td>[1011, 989, 990, 992, 993, 994, 991, 1003, 71,...</td>\n",
       "      <td>[0.9999976629195375, 0.999997407998317, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43855162</td>\n",
       "      <td>13</td>\n",
       "      <td>RMSE/ RMSLE loss function in Keras</td>\n",
       "      <td>&lt;p&gt;I try to participate in my first Kaggle com...</td>\n",
       "      <td>def root_mean_squared_error(y_true, y_pred):\\n...</td>\n",
       "      <td>&lt;python&gt;&lt;keras&gt;&lt;custom-function&gt;&lt;loss-function&gt;</td>\n",
       "      <td>[2, 258, 290, 932, 289, 117, 288, 175, 150, 108]</td>\n",
       "      <td>[0.999999246929511, 0.9999992116031092, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50253517</td>\n",
       "      <td>11</td>\n",
       "      <td>How to group functions without side effects?</td>\n",
       "      <td>&lt;p&gt;I have a function with several helper funct...</td>\n",
       "      <td>def create_filled_template_in_temp(path, value...</td>\n",
       "      <td>&lt;python&gt;</td>\n",
       "      <td>[433, 230, 973, 490, 425, 523, 515, 928, 477, ...</td>\n",
       "      <td>[0.9999991215290384, 0.999999073228489, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43791970</td>\n",
       "      <td>11</td>\n",
       "      <td>Pandas: assigning columns with multiple condit...</td>\n",
       "      <td>&lt;p&gt;Edited:&lt;/p&gt;\\n\\n&lt;p&gt;I have a financial portfo...</td>\n",
       "      <td>def closure():\\n    cur_weight = {}\\n    def f...</td>\n",
       "      <td>&lt;python&gt;&lt;pandas&gt;&lt;dataframe&gt;&lt;finance&gt;&lt;portfolio&gt;</td>\n",
       "      <td>[116, 117, 108, 256, 543, 1004, 934, 427, 92, ...</td>\n",
       "      <td>[0.9999995954184046, 0.9999995363726762, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44293479</td>\n",
       "      <td>11</td>\n",
       "      <td>Python, I'm repeating myself a lot when it com...</td>\n",
       "      <td>&lt;p&gt;Lets say I have three lists and I need to i...</td>\n",
       "      <td>def get_average(streaks):\\n    streak_0_num0s ...</td>\n",
       "      <td>&lt;python&gt;&lt;for-loop&gt;&lt;dry&gt;</td>\n",
       "      <td>[419, 102, 101, 100, 104, 425, 363, 523, 372, ...</td>\n",
       "      <td>[0.9999995399367301, 0.9999995397426804, 0.999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Post_Link_ID  Question_Score  \\\n",
       "0      50607128              47   \n",
       "1      45631715              36   \n",
       "2      43957860              17   \n",
       "3      44424040              16   \n",
       "4      48019843              14   \n",
       "5      42381902              13   \n",
       "6      43855162              13   \n",
       "7      50253517              11   \n",
       "8      43791970              11   \n",
       "9      44293479              11   \n",
       "\n",
       "                                      Question_Title  \\\n",
       "0  Creating a nested dictionary from a flattened ...   \n",
       "1      Downloading with chrome headless and selenium   \n",
       "2            Python unittest - Ran 0 tests in 0.000s   \n",
       "3      Django logging custom attributes in formatter   \n",
       "4                         PCA on word2vec embeddings   \n",
       "5  Interpreting negative Word2Vec similarity from...   \n",
       "6                 RMSE/ RMSLE loss function in Keras   \n",
       "7       How to group functions without side effects?   \n",
       "8  Pandas: assigning columns with multiple condit...   \n",
       "9  Python, I'm repeating myself a lot when it com...   \n",
       "\n",
       "                                    Question_Content  \\\n",
       "0  <p>I have a flattened dictionary which I want ...   \n",
       "1  <p>I'm using python-selenium and Chrome 59 and...   \n",
       "2  <p>So I want to do this code <a href=\"http://o...   \n",
       "3  <p>How can Django use logging to log using cus...   \n",
       "4  <p>I am trying to reproduce the results of thi...   \n",
       "5  <p>E.g. we train a word2vec model using <code>...   \n",
       "6  <p>I try to participate in my first Kaggle com...   \n",
       "7  <p>I have a function with several helper funct...   \n",
       "8  <p>Edited:</p>\\n\\n<p>I have a financial portfo...   \n",
       "9  <p>Lets say I have three lists and I need to i...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  def nest_dict(flat):\\n    result = {}\\n    for...   \n",
       "1  def enable_download_in_headless_chrome(self, d...   \n",
       "2  def test_add_returns_zero_for_emptyString(self...   \n",
       "3  def add_my_custom_attribute(record):\\n    reco...   \n",
       "4  def doPCA(pairs, embedding, num_components = 1...   \n",
       "5  def similarity(self, w1, w2):\\n    \"\"\"\\n    Co...   \n",
       "6  def root_mean_squared_error(y_true, y_pred):\\n...   \n",
       "7  def create_filled_template_in_temp(path, value...   \n",
       "8  def closure():\\n    cur_weight = {}\\n    def f...   \n",
       "9  def get_average(streaks):\\n    streak_0_num0s ...   \n",
       "\n",
       "                                                Tags  \\\n",
       "0    <python><dictionary><recursion><nested><netcdf>   \n",
       "1  <python><google-chrome><selenium><google-chrom...   \n",
       "2  <python><unit-testing><python-unittest><python...   \n",
       "3                          <python><django><logging>   \n",
       "4         <python><scikit-learn><nlp><pca><word2vec>   \n",
       "5        <python><nlp><similarity><gensim><word2vec>   \n",
       "6    <python><keras><custom-function><loss-function>   \n",
       "7                                           <python>   \n",
       "8    <python><pandas><dataframe><finance><portfolio>   \n",
       "9                            <python><for-loop><dry>   \n",
       "\n",
       "                                             func_id  \\\n",
       "0  [377, 421, 448, 371, 456, 100, 920, 150, 346, ...   \n",
       "1  [116, 416, 92, 1004, 258, 117, 102, 409, 430, ...   \n",
       "2   [2, 932, 929, 107, 313, 258, 255, 477, 458, 290]   \n",
       "3   [2, 258, 530, 289, 108, 117, 932, 290, 288, 489]   \n",
       "4  [349, 348, 497, 494, 498, 516, 527, 518, 519, ...   \n",
       "5  [1011, 989, 990, 992, 993, 994, 991, 1003, 71,...   \n",
       "6   [2, 258, 290, 932, 289, 117, 288, 175, 150, 108]   \n",
       "7  [433, 230, 973, 490, 425, 523, 515, 928, 477, ...   \n",
       "8  [116, 117, 108, 256, 543, 1004, 934, 427, 92, ...   \n",
       "9  [419, 102, 101, 100, 104, 425, 363, 523, 372, ...   \n",
       "\n",
       "                                                 sim  \n",
       "0  [0.9999984771395396, 0.9999984686083946, 0.999...  \n",
       "1  [0.9999992941886049, 0.9999992261907498, 0.999...  \n",
       "2  [0.9999963140780601, 0.9999960986804608, 0.999...  \n",
       "3  [0.9999994069389221, 0.9999993391644111, 0.999...  \n",
       "4  [0.9999985864775749, 0.9999984819488087, 0.999...  \n",
       "5  [0.9999976629195375, 0.999997407998317, 0.9999...  \n",
       "6  [0.999999246929511, 0.9999992116031092, 0.9999...  \n",
       "7  [0.9999991215290384, 0.999999073228489, 0.9999...  \n",
       "8  [0.9999995954184046, 0.9999995363726762, 0.999...  \n",
       "9  [0.9999995399367301, 0.9999995397426804, 0.999...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stack_overflow_partial=pd.read_pickle(\"data/SO_similarity_0_10.pkl\")\n",
    "df_stack_overflow_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Creating a nested dictionary from a flattened ...\n",
       "Name: Question_Title, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stack_overflow_partial[df_stack_overflow_partial[\"Post_Link_ID\"]==50607128][\"Question_Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([377, 421, 448, 371, 456, 100, 920, 150, 346, 416])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stack_overflow_partial[df_stack_overflow_partial[\"Post_Link_ID\"]==50607128][\"func_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_py100k=pd.read_pickle(\"data/py100k.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_py100k[700000:700100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_data_id=[]\n",
    "#for i in [260771, 275794, 428754, 372502, 360950, 284871, 412289, 412286, 11140, 412288]:\n",
    "#    #list_data_id.append(df_py100k.iloc[i][\"data_id\"])\n",
    "#    print(df_py100k.iloc[i])\n",
    "#    print()\n",
    "##df_py100k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
