{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 100 Android questions on Stack Overflow and the code snippets in the posts\n",
    "2. Andoid projects on Github (704,229 methods in the 1,000 Android repositories)\n",
    "\n",
    "*4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuous vector embedding of each code fragment at method–level granularity as \"document\".[13] FastText, a variation of Word2Vec algorithm.\n",
    "- Extracting Information from Source Code\n",
    "    - simple tokenizer: extract all words from source code by removing non–alphanumeric tokens.=> indifferenciable\n",
    "    - parser-based approach: traverse through the parse tree for each method, and extract information from the following syntactic categories. (Java-like)\n",
    "        - method name\n",
    "        - method invocation\n",
    "        - Enums\n",
    "        - String literals\n",
    "        - comments\n",
    "        - <strike>variable name</strike>\n",
    "- Building Vector Representations\n",
    "    - <strike>simply average embeddings</strike>\n",
    "    - Weighted average of all unique words in a document=> normalized tf-idf\n",
    "- Retrieval\n",
    "    - average the vector representations of constituent words to create a document embedding for the query sentence\n",
    "    - a standard similarity search algorithm to find the document vectors with closest cosine distance. => FAISS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. (2.1)把AST 轉成 a list of lists of keywords for each function\n",
    "2. (2.2)Train vector representation using the above lists\n",
    "3. (2.3) Calculate average weighted representation for each document (function)\n",
    "4. (3) evaluate using random benchmark test or TF-IDF benchmark test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: natural language queries <br>\n",
    "Output: related code fragments retrieved directly from Github code corpus<br><br>\n",
    "\n",
    "Map the Input into the same vector space as the codebase, and then calculate the vector distance of them in order to get the relevant result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric and choosing parameters of the model\n",
    "\n",
    "- Metric: select subsets of words from the document as simulated queries and then see if it can retrive the document, and then evaluate by the percentage of the documents that are retrieve back at top1 and top10. \n",
    "    - random benchmark test\n",
    "    - TF-IDF benchmark test => better performance\n",
    "- Parameters:\n",
    "    - embedding dimention=> 500\n",
    "    - three ways of combining word embeddings to document embeddings=> the conclusion is tf-idf better\n",
    "    - vector representation=> BM25 is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions?\n",
    "The paper mentions 2 evaluation approach: 1 uses Github only, the other one uses both GitHub and StackOverflow. I'm guessing the former one is for tuning in the development stage; while the later is the final evaluation for the completed system (NCS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
